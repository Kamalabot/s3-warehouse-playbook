{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:08:15.287291Z","iopub.execute_input":"2023-03-08T09:08:15.287671Z","iopub.status.idle":"2023-03-08T09:08:54.420803Z","shell.execute_reply.started":"2023-03-08T09:08:15.287638Z","shell.execute_reply":"2023-03-08T09:08:54.420058Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=eabd6555842a95b2e2cdc150f054819be098af73ed53a39e2e26e71a77448205\n  Stored in directory: /root/.cache/pip/wheels/5a/54/9b/a89cac960efb57c4c35d41cc7c9f7b80daa21108bc376339b7\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.7\n    Uninstalling py4j-0.10.9.7:\n      Successfully uninstalled py4j-0.10.9.7\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"Here are the different Spark Modules.\n \nSpark Core - RDD and Map Reduce APIs\n\nSpark Data Frames and Spark SQL\n\nSpark Structured Streaming\n\nSpark MLLib (Data Frame based)\n\nAs engineers, we need not focus too much on Spark Core libraries to build Data Pipelines. We should focus on Spark Data Frames as well as Spark SQL","metadata":{}},{"cell_type":"markdown","source":"Spark Cluster Manager Types\nLet us get an overview of different Spark Cluster Managers on which typically Spark Applications are deployed.\n\nHere are the supported cluster manager types.\n\nLocal (used for development and unit testing).\n\nStand Alone\n\nYARN\n\nMesos\nHere are the popular distributions which use YARN to deploy Spark Applications.\nCloudera\n\nAWS EMR\n\nGoogle Dataproc\n\nHortonworks\n\nMapR\n\nDatabricks uses Stand Alone for running or deploying Spark Job","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:39:19.048200Z","iopub.execute_input":"2023-03-08T08:39:19.048706Z","iopub.status.idle":"2023-03-08T08:39:19.060288Z","shell.execute_reply.started":"2023-03-08T08:39:19.048660Z","shell.execute_reply":"2023-03-08T08:39:19.058304Z"}}},{"cell_type":"markdown","source":"As part of this section we will get an overview about Data Processing using Spark with Python.\n\n    Pre-requisites and Objectives\n    \n    Starting Spark Context\n    \n    Overview of Spark read APIs\n    \n    Understand airlines data\n    \n    Inferring Schema\n    \n    Previewing airlines data\n    \n    Overview of Data Frame APIs\n    \n    Overview of Functions\n    \n    Overview of Spark Write APIs\n    \n    Reorganizing airlines data\n   \n    Previewing reorganized data\n    \n    Analyze and Understand Data\n    \n    Conclusion","metadata":{}},{"cell_type":"markdown","source":"et us say spark is of type SparkSession. There is an attribute as part of spark called as catalog and it is of type pyspark.sql.catalog.Catalog.\n\nWe can access catalog using spark.catalog.\n\nWe can permanently or temporarily create tables or views on top of data in a Data Frame.\n\nMetadata such as table names, column names, data types etc for the permanent tables or views will be stored in Metastore. We can access the metadata using spark.catalog \nwhich is exposed as part of SparkSession object.\n\nspark.catalog also provide us the details related to temporary views that are being created. Metadata of these temporary views will not be stored in Spark Metastore.\n\nPermanent tables are typically created using databases in spark metastore. If not specified, the tables will be created in default database.\n\nThere are several methods that are part of spark.catalog. We will explore them in the later topics.\n\nFollowing are some of the tasks that can be performed using spark.catalog object.\nCheck current database and switch to different databases.\n\nCreate permanent table in metastore.\n\nCreate or drop temporary views.\n\nRegister functions.\n\nAll the above tasks can be performed using SQL style commands passed to spark.sql.","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:08:54.422529Z","iopub.execute_input":"2023-03-08T09:08:54.422813Z","iopub.status.idle":"2023-03-08T09:08:54.477949Z","shell.execute_reply.started":"2023-03-08T09:08:54.422785Z","shell.execute_reply":"2023-03-08T09:08:54.476601Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"SparkSession is a class that is part of pyspark.sql package.It is a wrapper on top of Spark Context.\n\nWhen Spark application is submitted using spark-submit or spark-shell or pyspark, a web service called as Spark Context will be started.\n\nSpark Context maintains the context of all the jobs that are submitted until it is killed.\n\nSparkSession is nothing but wrapper on top of Spark Context.\n\nWe need to first create SparkSession object with any name. But typically we use spark. Once it is created, several APIs will be exposed including read.\n\nWe need to at least set Application Name and also specify the execution mode in \nwhich Spark Context should run while creating SparkSession object.\n\nWe can use appName to specify name for the application and master to specify the execution mode.\n\nBelow is the sample code snippet which will start the Spark Session object for u","metadata":{}},{"cell_type":"code","source":"spark = SparkSession. \\\n    builder. \\\n    config('spark.ui.port', '0'). \\\n    config(\"spark.sql.warehouse.dir\", f\"/kaggle/working/warehouse\"). \\\n    appName('Getting Started'). \\\n    getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:09:04.727921Z","iopub.execute_input":"2023-03-08T09:09:04.728288Z","iopub.status.idle":"2023-03-08T09:09:09.432002Z","shell.execute_reply.started":"2023-03-08T09:09:04.728256Z","shell.execute_reply":"2023-03-08T09:09:09.431028Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"23/03/08 09:09:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Read the data from different sources.\n\n    Files\n\n    Databases\n\n    Mainframes\n\n    APIs\n\nProcessing the data\n\n    Row Level Transformations\n\n    Aggregations\n\n    Sorting\n\n    Ranking\n\n    Joining multiple data sets\n\nWrite data to different targets.\n\n    Files\n\n    Databases\n\n    Mainframes\n\n    APIs","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:46:13.253650Z","iopub.execute_input":"2023-03-08T08:46:13.254569Z","iopub.status.idle":"2023-03-08T08:46:13.262001Z","shell.execute_reply.started":"2023-03-08T08:46:13.254518Z","shell.execute_reply":"2023-03-08T08:46:13.260466Z"}}},{"cell_type":"markdown","source":"All APIs are exposed under spark.read\n    \n    text - to read single column data from text files as well as reading each of the whole text file as one record.\n    \n    csv- to read text files with delimiters. Default is a comma, but we can use other delimiters as well.\n    \n    json - to read data from JSON files\n    \n    orc - to read data from ORC files\n    \n    parquet - to read data from Parquet files.\nWe can also read data from other file formats by plugging in and by using spark.read.format\n\nWe can also pass options based on the file formats.\n    inferSchema - to infer the data types of the columns based on the data.\n    header - to use header to get the column names in case of text files.\n    schema - to explicitly specify the schema.\n\nWe can get the help on APIs like spark.read.csv using help(spark.read.csv).\nReading delimited data from text files.","metadata":{}},{"cell_type":"code","source":"Trial_dataFrame = spark. \\\n    read. \\\n    csv(path='/kaggle/input/emr-dataset/Food_Establishment_Inspection_Data.csv',\n        header=True,\n       inferSchema=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:10:33.818762Z","iopub.execute_input":"2023-03-08T09:10:33.819155Z","iopub.status.idle":"2023-03-08T09:10:34.709569Z","shell.execute_reply.started":"2023-03-08T09:10:33.819122Z","shell.execute_reply":"2023-03-08T09:10:34.708681Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"Trial_dataFrame.show(2)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:10:41.183519Z","iopub.execute_input":"2023-03-08T09:10:41.183881Z","iopub.status.idle":"2023-03-08T09:10:41.342613Z","shell.execute_reply.started":"2023-03-08T09:10:41.183849Z","shell.execute_reply":"2023-03-08T09:10:41.341564Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"+----------------+------------------+---------------+--------------------+---------------+-------+--------+--------------+-------------+-----------+------------------------+--------------------+----------------+-----------------+--------------------------+--------------+---------------------+----------------+-----------+---------------------+-------------------+-----+\n|            Name|Program Identifier|Inspection Date|         Description|        Address|   City|Zip Code|         Phone|    Longitude|   Latitude|Inspection Business Name|     Inspection Type|Inspection Score|Inspection Result|Inspection Closed Business|Violation Type|Violation Description|Violation Points|Business_ID|Inspection_Serial_Num|Violation_Record_ID|Grade|\n+----------------+------------------+---------------+--------------------+---------------+-------+--------+--------------+-------------+-----------+------------------------+--------------------+----------------+-----------------+--------------------------+--------------+---------------------+----------------+-----------+---------------------+-------------------+-----+\n|#807 TUTTA BELLA|  #807 TUTTA BELLA|     08/31/2022|Seating 0-12 - Ri...|2746 NE 45TH ST|SEATTLE|   98105|(206) 722-6400|-122.29641473|47.66231092|        #807 TUTTA BELLA|Routine Inspectio...|              10|   Unsatisfactory|                     false|          BLUE| 3200 - Insects, r...|               5|  PR0089260|            DAEEWQC0L|          IVQ7QYW2V|    1|\n|#807 TUTTA BELLA|  #807 TUTTA BELLA|     08/31/2022|Seating 0-12 - Ri...|2746 NE 45TH ST|SEATTLE|   98105|(206) 722-6400|-122.29641473|47.66231092|        #807 TUTTA BELLA|Routine Inspectio...|              10|   Unsatisfactory|                     false|           RED| 0200 - Food Worke...|               5|  PR0089260|            DAEEWQC0L|          IV0J437H6|    1|\n+----------------+------------------+---------------+--------------------+---------------+-------+--------+--------------+-------------+-----------+------------------------+--------------------+----------------+-----------------+--------------------------+--------------+---------------------+----------------+-----------+---------------------+-------------------+-----+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can use options such as header and inferSchema to assign names and data types.\nHowever inferSchema will end up going through the entire data to assign schema. \n\nWe can use samplingRatio to process fraction of data and then infer the schema.\n\nIn case if the data in all the files have similar structure, we should be able to get the schema using one file and then apply it on others.\n\nIn our airlines data, schema is consistent across all the files and hence we should be able to get the schema by going through one file and apply on the entire dataset.","metadata":{}},{"cell_type":"code","source":"Trial_dataFrame.schema","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:10:54.357238Z","iopub.execute_input":"2023-03-08T09:10:54.357608Z","iopub.status.idle":"2023-03-08T09:10:54.367134Z","shell.execute_reply.started":"2023-03-08T09:10:54.357575Z","shell.execute_reply":"2023-03-08T09:10:54.365950Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"StructType([StructField('Name', StringType(), True), StructField('Program Identifier', StringType(), True), StructField('Inspection Date', StringType(), True), StructField('Description', StringType(), True), StructField('Address', StringType(), True), StructField('City', StringType(), True), StructField('Zip Code', StringType(), True), StructField('Phone', StringType(), True), StructField('Longitude', DoubleType(), True), StructField('Latitude', DoubleType(), True), StructField('Inspection Business Name', StringType(), True), StructField('Inspection Type', StringType(), True), StructField('Inspection Score', IntegerType(), True), StructField('Inspection Result', StringType(), True), StructField('Inspection Closed Business', BooleanType(), True), StructField('Violation Type', StringType(), True), StructField('Violation Description', StringType(), True), StructField('Violation Points', IntegerType(), True), StructField('Business_ID', StringType(), True), StructField('Inspection_Serial_Num', StringType(), True), StructField('Violation_Record_ID', StringType(), True), StructField('Grade', IntegerType(), True)])"},"metadata":{}}]},{"cell_type":"code","source":"Trial_dataFrame.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:11:10.292537Z","iopub.execute_input":"2023-03-08T09:11:10.292912Z","iopub.status.idle":"2023-03-08T09:11:10.300638Z","shell.execute_reply.started":"2023-03-08T09:11:10.292880Z","shell.execute_reply":"2023-03-08T09:11:10.299028Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"root\n |-- Name: string (nullable = true)\n |-- Program Identifier: string (nullable = true)\n |-- Inspection Date: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Address: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Zip Code: string (nullable = true)\n |-- Phone: string (nullable = true)\n |-- Longitude: double (nullable = true)\n |-- Latitude: double (nullable = true)\n |-- Inspection Business Name: string (nullable = true)\n |-- Inspection Type: string (nullable = true)\n |-- Inspection Score: integer (nullable = true)\n |-- Inspection Result: string (nullable = true)\n |-- Inspection Closed Business: boolean (nullable = true)\n |-- Violation Type: string (nullable = true)\n |-- Violation Description: string (nullable = true)\n |-- Violation Points: integer (nullable = true)\n |-- Business_ID: string (nullable = true)\n |-- Inspection_Serial_Num: string (nullable = true)\n |-- Violation_Record_ID: string (nullable = true)\n |-- Grade: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"yelpData = spark.read.json(path='/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:12:56.008093Z","iopub.execute_input":"2023-03-08T09:12:56.008504Z","iopub.status.idle":"2023-03-08T09:13:19.429416Z","shell.execute_reply.started":"2023-03-08T09:12:56.008466Z","shell.execute_reply":"2023-03-08T09:13:19.428420Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"yelpData.count()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:13:46.343197Z","iopub.execute_input":"2023-03-08T09:13:46.343595Z","iopub.status.idle":"2023-03-08T09:13:52.965162Z","shell.execute_reply.started":"2023-03-08T09:13:46.343563Z","shell.execute_reply":"2023-03-08T09:13:52.964405Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"6990280"},"metadata":{}}]},{"cell_type":"code","source":"yelpData.schema","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:15:20.032676Z","iopub.execute_input":"2023-03-08T09:15:20.033561Z","iopub.status.idle":"2023-03-08T09:15:20.040216Z","shell.execute_reply.started":"2023-03-08T09:15:20.033527Z","shell.execute_reply":"2023-03-08T09:15:20.039118Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"StructType([StructField('business_id', StringType(), True), StructField('cool', LongType(), True), StructField('date', StringType(), True), StructField('funny', LongType(), True), StructField('review_id', StringType(), True), StructField('stars', DoubleType(), True), StructField('text', StringType(), True), StructField('useful', LongType(), True), StructField('user_id', StringType(), True)])"},"metadata":{}}]},{"cell_type":"code","source":"yelpData.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:15:13.382553Z","iopub.execute_input":"2023-03-08T09:15:13.383922Z","iopub.status.idle":"2023-03-08T09:15:13.390889Z","shell.execute_reply.started":"2023-03-08T09:15:13.383879Z","shell.execute_reply":"2023-03-08T09:15:13.389659Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"root\n |-- business_id: string (nullable = true)\n |-- cool: long (nullable = true)\n |-- date: string (nullable = true)\n |-- funny: long (nullable = true)\n |-- review_id: string (nullable = true)\n |-- stars: double (nullable = true)\n |-- text: string (nullable = true)\n |-- useful: long (nullable = true)\n |-- user_id: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"yelpData.distinct().count()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:17:03.937846Z","iopub.execute_input":"2023-03-08T09:17:03.938255Z","iopub.status.idle":"2023-03-08T09:18:14.710607Z","shell.execute_reply.started":"2023-03-08T09:17:03.938224Z","shell.execute_reply":"2023-03-08T09:18:14.709417Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"6990280"},"metadata":{}}]},{"cell_type":"code","source":"Trial_dataFrame.distinct().count()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:16:17.332337Z","iopub.execute_input":"2023-03-08T09:16:17.332731Z","iopub.status.idle":"2023-03-08T09:16:21.373373Z","shell.execute_reply.started":"2023-03-08T09:16:17.332697Z","shell.execute_reply":"2023-03-08T09:16:21.372456Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"251455"},"metadata":{}}]},{"cell_type":"code","source":"Trial_dataFrame.distinct()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:16:17.332337Z","iopub.execute_input":"2023-03-08T09:16:17.332731Z","iopub.status.idle":"2023-03-08T09:16:21.373373Z","shell.execute_reply.started":"2023-03-08T09:16:17.332697Z","shell.execute_reply":"2023-03-08T09:16:21.372456Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"251455"},"metadata":{}}]},{"cell_type":"code","source":"attendants = [(1, \"Smith\", \"Deo\", 1086.0, \"Somalia\"),\n             (2, \"Kenry\", \"Jord\", 1950.0, \"Iran\"),\n             (3, \"Kick\", \"Boxer\", 7550.0, \"Kingome\"),\n             (4, \"Gill\", \"Nome\", 1500.0, \"New Wold\")\n            ]","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:21:21.796864Z","iopub.execute_input":"2023-03-08T09:21:21.797300Z","iopub.status.idle":"2023-03-08T09:21:21.804251Z","shell.execute_reply.started":"2023-03-08T09:21:21.797269Z","shell.execute_reply":"2023-03-08T09:21:21.803036Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"type(attendants)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:21:32.911178Z","iopub.execute_input":"2023-03-08T09:21:32.911690Z","iopub.status.idle":"2023-03-08T09:21:32.921175Z","shell.execute_reply.started":"2023-03-08T09:21:32.911654Z","shell.execute_reply":"2023-03-08T09:21:32.919841Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"attendantsDF = spark.createDataFrame(attendants,schema='''attendant_id INT, f_name STRING,\n                                     l_name STRING, salary FLOAT, Nationality STRING''')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:23:23.801094Z","iopub.execute_input":"2023-03-08T09:23:23.802675Z","iopub.status.idle":"2023-03-08T09:23:23.922095Z","shell.execute_reply.started":"2023-03-08T09:23:23.802615Z","shell.execute_reply":"2023-03-08T09:23:23.921069Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql.functions import *","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:38:19.507186Z","iopub.execute_input":"2023-03-08T09:38:19.507642Z","iopub.status.idle":"2023-03-08T09:38:19.514059Z","shell.execute_reply.started":"2023-03-08T09:38:19.507604Z","shell.execute_reply":"2023-03-08T09:38:19.512288Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"attendantsDF.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:24:10.400514Z","iopub.execute_input":"2023-03-08T09:24:10.400917Z","iopub.status.idle":"2023-03-08T09:24:11.429960Z","shell.execute_reply.started":"2023-03-08T09:24:10.400883Z","shell.execute_reply":"2023-03-08T09:24:11.429031Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"[Stage 25:>                                                         (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+------------+------+------+------+-----------+\n|attendant_id|f_name|l_name|salary|Nationality|\n+------------+------+------+------+-----------+\n|           1| Smith|   Deo|1086.0|    Somalia|\n|           2| Kenry|  Jord|1950.0|       Iran|\n|           3|  Kick| Boxer|7550.0|    Kingome|\n|           4|  Gill|  Nome|1500.0|   New Wold|\n+------------+------+------+------+-----------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"attendantsDF.select(\"f_name\",\"Nationality\").show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:25:42.140890Z","iopub.execute_input":"2023-03-08T09:25:42.141351Z","iopub.status.idle":"2023-03-08T09:25:42.403161Z","shell.execute_reply.started":"2023-03-08T09:25:42.141317Z","shell.execute_reply":"2023-03-08T09:25:42.402048Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"+------+-----------+\n|f_name|Nationality|\n+------+-----------+\n| Smith|    Somalia|\n| Kenry|       Iran|\n|  Kick|    Kingome|\n|  Gill|   New Wold|\n+------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"attendantsDF.withColumn('new_name',concat('Nationality',lit('_'),'l_name')).show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:37:30.026063Z","iopub.execute_input":"2023-03-08T09:37:30.026480Z","iopub.status.idle":"2023-03-08T09:37:30.250501Z","shell.execute_reply.started":"2023-03-08T09:37:30.026446Z","shell.execute_reply":"2023-03-08T09:37:30.249759Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"+------------+------+------+------+-----------+-------------+\n|attendant_id|f_name|l_name|salary|Nationality|     new_name|\n+------------+------+------+------+-----------+-------------+\n|           1| Smith|   Deo|1086.0|    Somalia|  Somalia_Deo|\n|           2| Kenry|  Jord|1950.0|       Iran|    Iran_Jord|\n|           3|  Kick| Boxer|7550.0|    Kingome|Kingome_Boxer|\n|           4|  Gill|  Nome|1500.0|   New Wold|New Wold_Nome|\n+------------+------+------+------+-----------+-------------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"attendantsDF.selectExpr(\"salary * 2 as new_salary\",\"concat(f_name,l_name) as new_fname\").show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:37:58.330730Z","iopub.execute_input":"2023-03-08T09:37:58.331158Z","iopub.status.idle":"2023-03-08T09:37:58.549360Z","shell.execute_reply.started":"2023-03-08T09:37:58.331114Z","shell.execute_reply":"2023-03-08T09:37:58.548298Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"+----------+---------+\n|new_salary|new_fname|\n+----------+---------+\n|    2172.0| SmithDeo|\n|    3900.0|KenryJord|\n|   15100.0|KickBoxer|\n|    3000.0| GillNome|\n+----------+---------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"attendantsDF.drop('Nationality').show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:26:12.521262Z","iopub.execute_input":"2023-03-08T09:26:12.522632Z","iopub.status.idle":"2023-03-08T09:26:12.809363Z","shell.execute_reply.started":"2023-03-08T09:26:12.522575Z","shell.execute_reply":"2023-03-08T09:26:12.808404Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"+------------+------+------+------+\n|attendant_id|f_name|l_name|salary|\n+------------+------+------+------+\n|           1| Smith|   Deo|1086.0|\n|           2| Kenry|  Jord|1950.0|\n|           3|  Kick| Boxer|7550.0|\n|           4|  Gill|  Nome|1500.0|\n+------------+------+------+------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"type(attendantsDF.drop('Nationality'))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:27:58.166151Z","iopub.execute_input":"2023-03-08T09:27:58.166560Z","iopub.status.idle":"2023-03-08T09:27:58.178453Z","shell.execute_reply.started":"2023-03-08T09:27:58.166524Z","shell.execute_reply":"2023-03-08T09:27:58.177242Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"pyspark.sql.dataframe.DataFrame"},"metadata":{}}]},{"cell_type":"code","source":"type(attendantsDF.drop('Nationality').collect()[0])","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:27:36.371122Z","iopub.execute_input":"2023-03-08T09:27:36.371532Z","iopub.status.idle":"2023-03-08T09:27:36.498170Z","shell.execute_reply.started":"2023-03-08T09:27:36.371497Z","shell.execute_reply":"2023-03-08T09:27:36.497439Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"pyspark.sql.types.Row"},"metadata":{}}]},{"cell_type":"code","source":"yelpData.write.parquet(path='/kaggle/working/',\n                       mode='append',\n                       compression='none')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:45:05.847001Z","iopub.execute_input":"2023-03-08T09:45:05.847403Z","iopub.status.idle":"2023-03-08T09:46:14.723569Z","shell.execute_reply.started":"2023-03-08T09:45:05.847372Z","shell.execute_reply":"2023-03-08T09:46:14.722186Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"!rm -f /kaggle/working/*.parquet","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:48:02.410650Z","iopub.execute_input":"2023-03-08T09:48:02.411150Z","iopub.status.idle":"2023-03-08T09:48:02.969507Z","shell.execute_reply.started":"2023-03-08T09:48:02.411115Z","shell.execute_reply":"2023-03-08T09:48:02.968378Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"yelpData.write.mode('append').option('compression','snappy'). \\\n    format('parquet').save('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:48:27.671614Z","iopub.execute_input":"2023-03-08T09:48:27.672005Z","iopub.status.idle":"2023-03-08T09:49:18.043854Z","shell.execute_reply.started":"2023-03-08T09:48:27.671953Z","shell.execute_reply":"2023-03-08T09:49:18.042854Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"yelpData.select('review_id').distinct().count()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:59:34.576610Z","iopub.status.idle":"2023-03-08T09:59:34.577315Z","shell.execute_reply.started":"2023-03-08T09:59:34.577075Z","shell.execute_reply":"2023-03-08T09:59:34.577101Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"[Stage 54:>                                                         (0 + 1) / 1]\r","output_type":"stream"}]},{"cell_type":"code","source":"!rm -f /kaggle/working/*.parquet","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:52:33.935747Z","iopub.execute_input":"2023-03-08T09:52:33.936108Z","iopub.status.idle":"2023-03-08T09:52:34.560540Z","shell.execute_reply.started":"2023-03-08T09:52:33.936079Z","shell.execute_reply":"2023-03-08T09:52:34.559601Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"yelpData.coalesce(1).write.mode('append').option('compression','none'). \\\n    option('sep','|').format('csv').save('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:57:42.341811Z","iopub.execute_input":"2023-03-08T09:57:42.342167Z","iopub.status.idle":"2023-03-08T09:58:52.018464Z","shell.execute_reply.started":"2023-03-08T09:57:42.342141Z","shell.execute_reply":"2023-03-08T09:58:52.016359Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"[Stage 54:>                 (0 + 1) / 1][Stage 55:>                 (0 + 1) / 1]\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1222639098.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myelpData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sep'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"yelpData. \\\n    coalesce(1). \\\n    write. \\\n    csv(f'/user/{username}/retail_db/order_items',\n        sep='|',\n        mode='overwrite',\n        compression='gzip'\n       )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.conf.set('spark.sql.shuffle.partitions', '2')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.sql(f\"CREATE DATABASE {username}_demo_db\")\nspark.sql(f\"DROP DATABASE IF EXISTS {username}_demo_db CASCADE\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.catalog.currentDatabase()\nspark.catalog.listDatabases()\nspark.catalog.setCurrentDatabase(f'{username}_demo_db')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = [(\"X\", )]\ndf = spark.createDataFrame(l, schema=\"dummy STRING\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql.functions import current_date\ndf.select(current_date()). \\\n    show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employees = [\n    (1, \"Tosk\", \"Ligk\", 1000.0, \n      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n    ),\n     (2, \"Kern\", \"Lork\", 1250.0, \n      \"India\", \"+91 234 128 8901\", \"456 78 9123\"\n     ),\n     (3, \"Firk\", \"John\", 750.0, \n      \"united KINGDOM\", \"+84 521 585 1111\", \"222 33 4444\"\n     ),\n     (4, \"Back\", \"Rown\", 1500.0, \n      \"AUSTRALIA\", \"+6657 86 214 558\", \"789 12 6118\"\n     )\n]","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:14:53.030781Z","iopub.execute_input":"2023-03-08T10:14:53.031223Z","iopub.status.idle":"2023-03-08T10:14:53.040659Z","shell.execute_reply.started":"2023-03-08T10:14:53.031166Z","shell.execute_reply":"2023-03-08T10:14:53.038619Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"employeesDF = spark. \\\n    createDataFrame(employees,\n                    schema=\"\"\"employee_id INT, first_name STRING, \n                    last_name STRING, salary FLOAT, nationality STRING,\n                    phone_number STRING, ssn STRING\"\"\"\n                   )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.sql('SHOW PARTITIONS orders_part').show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.write.saveAsTable(\"dual\", mode='overwrite')\ndf.write.insertInto()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orders. \\\n    write. \\\n    saveAsTable(\n        'orders_part',\n        mode='overwrite',\n        partitionBy='order_month'\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.catalog. \\\n    createExternalTable(\"airport_codes\",\n                        path=airport_codes_path,\n                        source=\"csv\",\n                        sep=\"\\t\",\n                        header=\"true\",\n                        inferSchema=\"true\"\n                       )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.sql('DESCRIBE FORMATTED airport_codes').show(100, False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"park.read.table(\"airport_codes\").show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.catalog.listColumns('airport_codes')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.sql(\"DROP TABLE dual\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can use CASCADE to drop database along with tables.\nspark.sql(f\"DROP DATABASE IF EXISTS {username}_demo_db CASCADE\")\nspark.sql(\"DROP TABLE dual\")\nspark.sql(f\"DROP DATABASE {username}_demo_db\")","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:11:51.724735Z","iopub.execute_input":"2023-03-08T10:11:51.725193Z","iopub.status.idle":"2023-03-08T10:11:51.742901Z","shell.execute_reply.started":"2023-03-08T10:11:51.725139Z","shell.execute_reply":"2023-03-08T10:11:51.741264Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1445774334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We can use CASCADE to drop database along with tables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DROP DATABASE IF EXISTS {username}_demo_db CASCADE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DROP TABLE dual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"],"ename":"NameError","evalue":"name 'spark' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"When we want to create a table using spark.catalog.createTable or using spark.catalog.createExternalTable, we need to specify Schema.\n\nSchema can be inferred or we can pass schema using StructType object while creating the table..\n\nStructType takes list of objects of type StructField.\n\nStructField is built using column name and data type. All the data types are available under pyspark.sql.types.\n\nWe need to pass table name and schema for spark.catalog.createTable.\n\nWe have to pass path along with name and schema for spark.catalog.createExternalTable","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.types import StructField, StructType, \\\n    IntegerType, StringType, FloatType","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employeesSchema = StructType([\n    StructField(\"employee_id\", IntegerType()),\n    StructField(\"first_name\", StringType()),\n    StructField(\"last_name\", StringType()),\n    StructField(\"salary\", FloatType()),\n    StructField(\"nationality\", StringType())\n])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employeesSchema.simpleString()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.catalog.createTable(\"employees\", schema=employeesSchema)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.sql('DESCRIBE FORMATTED employees').show(100, truncate=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark. \\\n    read. \\\n    csv(orders_path,\n        schema='''order_id INT, order_date DATE,\n                  order_customer_id INT, order_status STRING\n               '''\n       ). \\\n    withColumn('order_month', date_format('order_date', 'yyyyMM')). \\\n    write. \\\n    partitionBy('order_month'). \\\n    parquet(f'/user/{username}/retail_db/orders_part')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark. \\\n    catalog. \\\n    createTable('orders_part',\n                path=f'/user/{username}/retail_db/orders_part',\n                source='parquet'\n               )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.sql('SHOW PARTITIONS orders_part').show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.catalog.recoverPartitions('orders_part')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark.read.table('orders_part'). \\\n    groupBy('order_month'). \\\n    count(). \\\n    show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"airport_codes_df.createTempView(\"airport_codes_v\")","metadata":{},"execution_count":null,"outputs":[]}]}